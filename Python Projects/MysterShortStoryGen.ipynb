{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Mystery Short Story Idea Generator\n",
        "By Kenny Drewry & Piyush Makkapati"
      ],
      "metadata": {
        "id": "m7r-DDaRoOK_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDg_6TG8XKcN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd77384e-6f7e-4a02-d09e-c84032c42732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 198
        }
      ],
      "source": [
        "#import all necessary packages for text processing and random generation\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "from collections import Counter\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('brown')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Build the data structures for title, first sentence, and last sentence from our data.\n",
        "\n",
        "#open the data file\n",
        "with open(\"short stories.txt\", \"r\") as fh:\n",
        "    fh_raw = fh.readlines()\n",
        "    fh.close()\n",
        "#arrays to hold all the different titles and first and last sentecnes fomr the different mystery stories\n",
        "titles = []\n",
        "first = []\n",
        "last = []\n",
        "#loop through the data file and append to above lists\n",
        "#each unique mystery story will have 3 lines associated with it, then 1 blank (must skip a line)\n",
        "for i in range(0, len(fh_raw) - 3, 4):\n",
        "  titles.append(fh_raw[i].replace(\"\\n\", ''))\n",
        "  first.append(fh_raw[i+1].replace(\"\\n\", ''))\n",
        "  last.append(fh_raw[i+2].replace(\"\\n\", ''))\n",
        "\n",
        "#the data file has been processed, so each list above must now be cut up into words\n",
        "titleWords = []\n",
        "for title in titles:\n",
        "  #split each title by whitespace\n",
        "  wordList = title.split()\n",
        "  #add each word into the word list associated\n",
        "  for word in wordList:\n",
        "    titleWords.append(word.lower())\n",
        "\n",
        "#repeat for first and last sentences\n",
        "firstWords = []\n",
        "for line in first:\n",
        "  wordList = line.split()\n",
        "  for word in wordList:\n",
        "    firstWords.append(word.lower())\n",
        "\n",
        "lastWords = []\n",
        "for line in last:\n",
        "  wordList = line.split()\n",
        "  for word in wordList:\n",
        "    lastWords.append(word.lower())"
      ],
      "metadata": {
        "id": "-AVWtNbUdOEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#builds a data structure to hold words and what follows them\n",
        "def nextWord(arr):\n",
        "  words = {} #dictionary that will hold the words and what follows them (word: [following words])\n",
        "  #keep count of what index the loop is on so the following word can be gathered\n",
        "  i = 0\n",
        "  #loop through each word in the array\n",
        "  for word in arr:\n",
        "    #add an entry to dictionary if the word is not already there.\n",
        "    if words.get(word, -1) == -1:\n",
        "      #add new entry since word is not in dictionary using the array and index\n",
        "      try:\n",
        "        words.update({word: [arr[i+1]]})\n",
        "      except IndexError:\n",
        "        a = 0 #do nothing as there is no following word\n",
        "    else:\n",
        "      try:\n",
        "        #add following word to the already existing entry using the array and index\n",
        "        words[word].append(arr[i+1])\n",
        "      except IndexError:\n",
        "        a = 0 #do nothing as there is no following word\n",
        "    i += 1\n",
        "  return words\n",
        "\n",
        "#use the above function to create data structures for title, first sentence, and last sentence using the word lists created above\n",
        "nextFirst = nextWord(firstWords)\n",
        "nextLast = nextWord(lastWords)\n",
        "nextTitle = nextWord(titleWords)"
      ],
      "metadata": {
        "id": "BeLznrxtJTEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#function to get a random next word from the dictionary of words to following words\n",
        "def mystery_nextword(term, words):\n",
        "  try:\n",
        "    #get list of following words for term\n",
        "    curWords = words[term]\n",
        "    #randomly generate a number between 0 and the length of the list of following words\n",
        "    #to pseudorandomize the picking of the next word in the sequence\n",
        "    num2 = random.randint(0, len(curWords)-1)\n",
        "    #use the randomly generated number to get word at the index of the randomly generated number\n",
        "    curWord = curWords[num2]\n",
        "    #return the word\n",
        "    return curWord\n",
        "  except:\n",
        "    #return -1 if the word doesn't exist in the dictionary or does not have any following words\n",
        "    return -1"
      ],
      "metadata": {
        "id": "DU4uck4nmgr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generation for titles\n",
        "def titleGenerator(words):\n",
        "  #randomly generate a title size\n",
        "  size = random.randint(3, 8)\n",
        "  #hold the new title in a list of strings\n",
        "  title = []\n",
        "  fir = True\n",
        "  #generate more words for the title, only while the title is less than the randomly assigned length\n",
        "  while len(title) < size:\n",
        "    #about 80% of the time, the titles begin with the word the so the first word is more heavily weighted to be \"the\"\n",
        "    if(fir):\n",
        "      fir = False\n",
        "      #generate random number to see if \"the\" will be the chosen word\n",
        "      num = random.randint(0, len(words)-1)\n",
        "      #\"the\" will be  the chosen word only if it is divisible by 2, 3, or 5 to simulate a higher chance of it being selected.\n",
        "      if num % 2 == 0 or num % 3 == 0 or num % 5 == 0:\n",
        "        #add word to the output list\n",
        "        title.append(\"the\")\n",
        "        #set curWord so the next word can be generated\n",
        "        curWord = 'the'\n",
        "      #if the randomly generated number is not divisible, choose another random word to start the title\n",
        "      else:\n",
        "        #get all the words in the dictionary and put into a list, so a random one can be selected\n",
        "        keys = list(words.keys())\n",
        "        #add word to the output list\n",
        "        title.append(keys[num])\n",
        "        #set curWord so the next word can be generated\n",
        "        curWord = keys[num]\n",
        "    #only enters if not the first time through while\n",
        "    #generate next word based on the curWord\n",
        "    else:\n",
        "      curWord = mystery_nextword(curWord, words)\n",
        "      #check to see if a word was actually found, do not append if word is not found\n",
        "      if(curWord != -1):\n",
        "        title.append(curWord)\n",
        "  return title\n",
        "\n",
        "#generation for (first and last) sentences\n",
        "def sentenceGenerator(words):\n",
        "  #make list of strings to hold output\n",
        "  sentence = []\n",
        "  fir = True\n",
        "  #randomly generate a sentence size\n",
        "  size = random.randint(2,15)\n",
        "  curWord = ''\n",
        "  #generate more words for the sentence, only while its length is less than the randomly assigned length\n",
        "  while len(sentence) < size:\n",
        "    #upon first iteration, we must generate a random word to build the sentence off of\n",
        "    if(fir):\n",
        "      fir = False\n",
        "      #generate random number to randomize the word chosen\n",
        "      num = random.randint(0, len(words)-1)\n",
        "      #get all words in the dictionary into a list to select randomly using index\n",
        "      keys = list(words.keys())\n",
        "      #append first word to sentence list\n",
        "      sentence.append(keys[num])\n",
        "      curWord = keys[num]\n",
        "      #generate next word after the first word and append\n",
        "      curWord = mystery_nextword(curWord, words)\n",
        "      if(curWord != -1):\n",
        "        sentence.append(curWord)\n",
        "    #after first iteration, get new word based on the previous word\n",
        "    else:\n",
        "      curWord = mystery_nextword(curWord, words)\n",
        "      #only append word to sentence list if it exists\n",
        "      if(curWord != -1):\n",
        "        sentence.append(curWord)\n",
        "      else:\n",
        "        #in case word is not found, generate a completely new word to build from\n",
        "        fir = True\n",
        "  #return the list of words for the new sentence\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "MHbijKf_QUJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#generate a title, first sentence, and last sentence using the functions above\n",
        "def generate(nextTitle, nextFirst, nextLast):\n",
        "  #build output string for the output file\n",
        "  output = 'Title: '\n",
        "\n",
        "  #generate the new title and sentences using the next dictionaries\n",
        "  titleSet = titleGenerator(nextTitle)\n",
        "  firstSet = sentenceGenerator(nextFirst)\n",
        "  lastSet = sentenceGenerator(nextLast)\n",
        "\n",
        "  #each word in the titles and sentences are in a list\n",
        "  #loop through the list for formatting of the title and sentences\n",
        "  for word in titleSet:\n",
        "    #all words are capitalized in the title\n",
        "    output += word.capitalize() + \" \"\n",
        "  output += '\\nFirst Sentence: '\n",
        "  fir = True\n",
        "  for word in firstSet:\n",
        "    if(fir):\n",
        "      #only first word is capitalized in the sentence\n",
        "      output += word.capitalize() + \" \"\n",
        "      fir = False\n",
        "    else:\n",
        "      output += word + \" \"\n",
        "  output += '\\nLast Sentence: '\n",
        "  fir = True\n",
        "  for word in lastSet:\n",
        "    if(fir):\n",
        "      #only first word is capitalized in the sentence\n",
        "      output += word.capitalize() + \" \"\n",
        "      fir = False\n",
        "    else:\n",
        "      output += word + \" \"\n",
        "  #add extra newline for readability in file\n",
        "  output += \"\\n\"\n",
        "\n",
        "  #return the output string\n",
        "  return output\n",
        "\n",
        "#generate a large amount of titles and sentences to place in output file\n",
        "#each new idea is 3 lines (title, first, last) with a blank line following\n",
        "for i in range(0, 50):\n",
        "  with open(\"output.txt\", \"a\") as output:\n",
        "    output.write(generate(nextTitle, nextFirst, nextLast))\n",
        "    output.write(\"\\n\")"
      ],
      "metadata": {
        "id": "m4al30VLvaUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code is used for calculations for the bestsellers data."
      ],
      "metadata": {
        "id": "JJKHRv0jv28u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/491 Final Project/Abandoned in death/Abandoned in death.txt') as b1:\n",
        "    blob = TextBlob(b1.read())\n",
        "    temp1 = blob.split()\n",
        "    print(\"Character count: \" + str(len(blob))) # grab the character count of the entire txt file\n",
        "    adj = 0\n",
        "    verb = 0\n",
        "    for (word, tag) in blob.tags:\n",
        "      if tag == 'JJ':\n",
        "        adj = adj + 1\n",
        "    print(\"Number of Adjectives: \" + str(adj))\n",
        "    temp = Counter(temp1).most_common(5)\n",
        "    print(temp)\n",
        "b1.close()\n",
        "    \n",
        "# print(blob.tags)"
      ],
      "metadata": {
        "id": "a7VVGQnSQ6lo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "20988fa0-f7f0-49af-d907-a6f3400adffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-ebea3c71a5c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/491 Final Project/Abandoned in death/Abandoned in death.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mblob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextBlob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtemp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Character count: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# grab the character count of the entire txt file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/491 Final Project/Abandoned in death/Abandoned in death.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# \n",
        "with open('/content/drive/MyDrive/491 Final Project/Death on the Nile/(Hercule Poirot 15) Agatha Christie - Death on the Nile (2001).txt') as b2:\n",
        "    blob = TextBlob(b2.read())\n",
        "    temp1 = blob.split()\n",
        "    print(\"Character count: \" + str(len(blob))) # grab the character count of the entire txt file\n",
        "    adj = 0\n",
        "    verb = 0\n",
        "    for (word, tag) in blob.tags:\n",
        "      if tag == 'JJ':\n",
        "        adj = adj + 1\n",
        "    print(\"Number of Adjectives: \" + str(adj))\n",
        "    temp = Counter(temp1).most_common(5)\n",
        "    print(temp)\n",
        "b2.close()\n"
      ],
      "metadata": {
        "id": "Mb1bUY6pVqry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e979047-1751-4428-d246-b2bf5c7d97a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character count: 170399\n",
            "Number of Adjectives: 2117\n",
            "[('the', 985), ('to', 626), ('a', 625), ('of', 556), ('and', 513)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/491 Final Project/The Camel Club/David Baldacci - The Camel Club-Warner Vision Books (2006) (1).txt') as b3:\n",
        "    blob = TextBlob(b3.read())\n",
        "    temp1 = blob.split()\n",
        "    print(\"Character count: \" + str(len(blob))) # grab the character count of the entire txt file\n",
        "    adj = 0\n",
        "    verb = 0\n",
        "    for (word, tag) in blob.tags:\n",
        "      if tag == 'JJ':\n",
        "        adj = adj + 1\n",
        "    print(\"Number of Adjectives: \" + str(adj))\n",
        "    temp = Counter(temp1).most_common(5)\n",
        "    print(temp)\n",
        "b3.close()"
      ],
      "metadata": {
        "id": "7F_4iY-3VrG0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82860c25-cba9-4b52-97f7-dd7837f13091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character count: 151376\n",
            "Number of Adjectives: 2157\n",
            "[('the', 1446), ('and', 664), ('a', 639), ('to', 589), ('of', 554)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/491 Final Project/The Maid/Nita Prose - The Maid full book (2021) (1).txt') as b4:\n",
        "    blob = TextBlob(b4.read())\n",
        "    temp1 = blob.split()\n",
        "    print(\"Character count: \" + str(len(blob))) # grab the character count of the entire txt file\n",
        "    adj = 0\n",
        "    verb = 0\n",
        "    for (word, tag) in blob.tags:\n",
        "      if tag == 'JJ':\n",
        "        adj = adj + 1\n",
        "    print(\"Number of Adjectives: \" + str(adj))\n",
        "    temp = Counter(temp1).most_common(5)\n",
        "    print(temp)\n",
        "b4.close()"
      ],
      "metadata": {
        "id": "dWLTcg_HVri7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b413eef-1891-4feb-ebbd-98d04a5b7421"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character count: 134969\n",
            "Number of Adjectives: 2046\n",
            "[('the', 1081), ('I', 992), ('to', 641), ('a', 536), ('and', 527)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/491 Final Project/The Thursday Murder club/(1) Richard Osman - Thursday Murder Club (2020) (1).txt') as b5:\n",
        "    blob = TextBlob(b5.read())\n",
        "    temp1 = blob.split()\n",
        "    print(\"Character count: \" + str(len(blob))) # grab the character count of the entire txt file\n",
        "    adj = 0\n",
        "    verb = 0\n",
        "    for (word, tag) in blob.tags:\n",
        "      if tag == 'JJ':\n",
        "        adj = adj + 1\n",
        "    print(\"Number of Adjectives: \" + str(adj))\n",
        "    temp = Counter(temp1).most_common(5)\n",
        "    print(temp)\n",
        "b5.close()"
      ],
      "metadata": {
        "id": "UhbBnlYnVrxH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce983069-76dc-488d-8431-8ae177f7e301"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Character count: 122084\n",
            "Number of Adjectives: 1575\n",
            "[('the', 912), ('to', 593), ('a', 582), ('and', 526), ('of', 354)]\n"
          ]
        }
      ]
    }
  ]
}